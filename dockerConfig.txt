
docker exec -it <container name> /bin/bash

docker run -d --hostname host-rabbit --name rabbitmq -p 5672:5672 -p 15672:15672 --restart unless-stopped rabbitmq:3.7-management

docker run --name zookeepermy -p 2181:2181 --restart unless-stopped -d zookeeper

docker run -e DS_LICENSE=accept -p 9042:9042 --restart unless-stopped --name my-dse -d datastax/dse-server:6.0.2

docker run --name spark-master -p 8080:8080 -p 7077:7077 --restart unless-stopped -h spark-master -e ENABLE_INIT_DAEMON=false -d
bde2020/spark-master:2.1.1-hadoop2.7

docker run --name spark-worker-1 -p 8081:8081 --restart unless-stopped --link spark-master:spark-master -e ENABLE_INIT_DAEMON=false -d bde2020/spark-worker:2.1.1-hadoop2.7

docker run -e DS_LICENSE=accept --link my-dse -p 9091:9091 --memory 1g --name my-studio -d datastax/dse-studio

http://spring-projects.ru/projects/spring-amqp/

https://www.wisdomjobs.com/e-university/apache-zookeeper-tutorial-1739/zookeeper-fundamentals-19683.html

https://spring.io/guides/gs/messaging-rabbitmq/

https://www.rabbitmq.com/api-guide.html

https://crypticarticles.wordpress.com/2017/03/09/spark-cassandra-java-connector-example/

mvn install

java -cp target/scrzs-1.0-SNAPSHOT-jar-with-dependencies.jar by.intexsoft.scrzs.Runner

java -jar target/scrzs-1.0-SNAPSHOT.jar

<================================zookeeper=================================>
https://www.baeldung.com/java-zookeeper

bin/zkServer.sh start

bin/zkCli.sh

create /node_name my_data

#Spark-Cassandra zookeeper config
create /Spark/Cassandra/connection_host 192.168.99.100
create /Spark/Cassandra/keyspace mykeyspace
create /Spark/submit_deployMode client
create /Spark/app_name mysparkapp
create /Spark/cores_max 1
create /Spark/master_url spark://192.168.99.100:7077
create /Spark/context_jar ./target/scrzs-1.0-SNAPSHOT.jar

<==============================spark-working-version==========================>

docker run --name spark-master162 -p 8080:8080 -p 7077:7077 --restart unless-stopped -h spark-master -e ENABLE_INIT_DAEMON=false -d bde2020/spark-master:1.6.2-hadoop2.6

docker run --name spark-worker-162 -p 8081:8081 --restart unless-stopped --link spark-master162:spark-master -e ENABLE_INIT_DAEMON=false -d bde2020/spark-worker:1.6.2-hadoop2.6

bin/spark-shell --packages "com.datastax.spark":"spark-cassandra-connector_2.10":"1.6.2"

<====================================rabbit-messages===========================>

{ 
	"userid": 88055555,
    "username": "userFromJsonMessage",
	"firstname": "James",
	"lastname": "Oflin",
	"age": 72,
	"phonenumber": "+4819213213"
}
















